# Project Structure

Complete file structure for the Personal Codex Agent project.

```
personal-codex-agent/
â”‚
â”œâ”€â”€ ðŸ“„ README.md                 # Main project documentation
â”œâ”€â”€ ðŸ“„ DEPLOYMENT.md            # Deployment guide
â”œâ”€â”€ ðŸ“„ PROJECT_STRUCTURE.md     # This file
â”‚
â”œâ”€â”€ âš™ï¸ requirements.txt          # Python dependencies
â”œâ”€â”€ âš™ï¸ .env.example              # Environment template
â”œâ”€â”€ âš™ï¸ .gitignore                # Git ignore rules
â”‚
â”œâ”€â”€ ðŸ³ Dockerfile                # Docker configuration
â”œâ”€â”€ ðŸ³ docker-compose.yml       # Docker Compose setup
â”œâ”€â”€ ðŸš€ run.sh                    # Local run script
â”‚
â”œâ”€â”€ ðŸŽ¯ app.py                    # Main Streamlit application
â”œâ”€â”€ ðŸ§ª test_agent.py            # Testing script
â”‚
â”œâ”€â”€ ðŸ“ src/                      # Source code directory
â”‚   â”œâ”€â”€ __init__.py              # Package initialization
â”‚   â”œâ”€â”€ config.py                # Configuration management
â”‚   â”œâ”€â”€ document_processor.py   # Document handling & chunking
â”‚   â”œâ”€â”€ vector_store.py         # FAISS vector database
â”‚   â””â”€â”€ chat_agent.py           # RAG chat agent
â”‚
â”œâ”€â”€ ðŸ“ .streamlit/              # Streamlit configuration (optional)
â”‚   â””â”€â”€ secrets.toml            # Streamlit Cloud secrets
â”‚
â”œâ”€â”€ ðŸ“ data/                    # Data directory (optional)
â”‚   â”œâ”€â”€ uploads/                # Uploaded documents
â”‚   â””â”€â”€ processed/              # Processed chunks
â”‚
â””â”€â”€ ðŸ“ docs/                    # Additional documentation (optional)
    â”œâ”€â”€ api.md                  # API documentation
    â”œâ”€â”€ architecture.md         # System architecture
    â””â”€â”€ examples/               # Example documents
```

## ðŸ“„ File Descriptions

### Core Application Files

**`app.py`**
- Main Streamlit application
- UI components and user interaction
- File upload and document processing
- Chat interface with mode selection
- Session state management

**`src/config.py`**
- Centralized configuration
- Environment variable handling
- Model and parameter settings
- Validation logic

**`src/document_processor.py`**
- Document parsing (PDF, DOCX, TXT)
- Text extraction and cleaning
- Sentence-boundary aware chunking
- Token counting and overlap handling
- Metadata management

**`src/vector_store.py`**
- FAISS vector database interface
- OpenAI embedding generation
- Similarity search implementation
- Statistics and analytics
- Batch processing for efficiency

**`src/chat_agent.py`**
- RAG-powered conversational agent
- Mode-specific response generation
- Context retrieval and assembly
- LLM prompt engineering
- Response formatting

### Configuration Files

**`requirements.txt`**
```
streamlit==1.29.0
openai==1.6.1
faiss-cpu==1.7.4
sentence-transformers==2.2.2
pypdf2==3.0.1
python-docx==0.8.11
tiktoken==0.5.2
numpy==1.24.3
pandas==2.0.3
python-dotenv==1.0.0
plotly==5.17.0
```

**`.env.example`**
```
OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-3.5-turbo
# EMBEDDING_MODEL=text-embedding-3-small
```

### Deployment Files

**`Dockerfile`**
- Multi-stage Docker build
- Python 3.9 slim base image
- System dependency installation
- Application setup and configuration

**`docker-compose.yml`**
- Service definition
- Port mapping and environment
- Health checks
- Volume mounting for data persistence

**`run.sh`**
- Local development script
- Environment setup
- Virtual environment management
- Streamlit launch with proper configuration

### Testing & Validation

**`test_agent.py`**
- End-to-end system testing
- Sample document creation
- Component validation
- Integration testing
- Performance verification

## ðŸ—‚ï¸ Data Flow

### Document Processing Flow
```
Upload â†’ Extract â†’ Chunk â†’ Embed â†’ Store
  â†“        â†“        â†“       â†“       â†“
Files â†’ Text â†’ Sentences â†’ Vectors â†’ FAISS
```

### Query Processing Flow
```
Question â†’ Embed â†’ Search â†’ Retrieve â†’ Generate â†’ Response
    â†“        â†“       â†“        â†“         â†“         â†“
  Text â†’ Vector â†’ FAISS â†’ Context â†’ LLM â†’ Answer
```

## ðŸ”§ Component Dependencies

```mermaid
graph TD
    A[app.py] --> B[DocumentProcessor]
    A --> C[VectorStore]
    A --> D[ChatAgent]
    B --> E[Config]
    C --> E
    D --> C
    D --> E
    C --> F[OpenAI API]
    D --> F
    B --> G[File Parsers]
    G --> H[PyPDF2]
    G --> I[python-docx]
    C --> J[FAISS]
    A --> K[Streamlit]
```

## ðŸ“Š Memory Usage

### Typical Memory Footprint
- **Base Application**: ~50MB
- **Document Processing**: +10-50MB per document
- **Vector Storage**: ~4 bytes Ã— dimensions Ã— chunks
- **FAISS Index**: ~1.5x vector storage size

### Example Calculation
```
10 documents Ã— 20 chunks each Ã— 1536 dimensions Ã— 4 bytes = ~1.2